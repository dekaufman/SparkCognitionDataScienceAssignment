---
title: "SparkCognition Data Science Test Project:  Targeting of Insurance Marketing"
output: html_notebook
---

```{r setup, message=FALSE, warning=FALSE}
library(tidyverse)
library(gridExtra)
library(knitr)
library(kableExtra)
library(randomForest)

setwd('C:/Users/David/Documents/Me/Energy/Jobs/2018/SparkCognition/SparkCognitionDataScienceAssignment')
```

### Ingest training data and report dimensions
```{r, message=FALSE, warning=FALSE}
df_train_orig <- read_csv('marketing_training.csv')
# %>% 
#   mutate_if(is.character, as.factor) 

dim(df_train_orig)
```
## Generate descriptive statistics on individual features
Separate the features into categorical and numeric, for separate descriptive methods
```{r}
df_train_numeric <- df_train_orig %>% select_if(is.numeric)
df_train_categ <- df_train_orig %>% select_if(is.character)
```

### Summarize categorical variables
```{r}
# Make tidy
df_cat_tidy <- df_train_categ %>% 
  gather('feature', 'value', 1:11)
# Count values
df_cat_dists <- df_cat_tidy %>% 
  group_by(feature, value) %>% 
  summarise(count = n()) %>% 
  ungroup() %>% 
  arrange(feature, desc(count))
# Compute distributions
df_cat_dists <- df_cat_dists %>% 
  group_by(feature) %>% 
  mutate(share = count / sum(count))
```

### Visualize categorical variables
```{r fig.width=10, fig.height=10}
fn_make_hist <- function(var_name, data_frame) {
  df_current_col <- data_frame %>% filter(feature == var_name)
  graph <- ggplot(data = df_current_col, 
                   aes(x = reorder(value, -share), y = share)) +
    geom_col() +
    stat_identity(geom="text", aes(label=count), vjust=-0.5, size = 3) +
    labs(x = var_name) +
    coord_cartesian(ylim = c(0, 1))
  if (nrow(df_current_col) > 4) {
    graph <- graph + theme(axis.text.x = element_text(angle = 45, hjust = 1))
  } 
  return(graph)
}

l_histograms <- lapply(colnames(df_train_categ), fn_make_hist, data_frame = df_cat_dists)

# Assemble set of histograms
grid.arrange(grobs = l_histograms, nrow = 4)
```

### Descriptive stats for numerical variables
```{r warning=FALSE, rows.print = 25, results = 'asis'}
# Source:  https://stackoverflow.com/a/34594642

# Compute quantiles, etc.
df_train_numer_stats <- df_train_numeric %>%
  summarise_all(funs(min = min, 
                     q25 = quantile(., 0.25), 
                     median = median, 
                     q75 = quantile(., 0.75), 
                     max = max,
                     mean = mean, 
                     sd = sd), 
                 na.rm = TRUE)

# Count NAs by column
df_train_numer_num_na <- df_train_numeric %>%
  summarise_all(funs(numNA = sum(is.na(.))))

df_train_numer_stats <- df_train_numer_stats %>% bind_cols(df_train_numer_num_na)

# Reshape back to tidy format
df_train_numer_stats <- df_train_numer_stats %>% 
  gather(stat, val) %>%
  separate(stat, into = c("var", "stat"), sep = "_") %>%
  spread(stat, val) %>%
  select(var, min, q25, median, q75, max, mean, sd, numNA) # reorder columns

# Pretty table printing; cf. http://haozhu233.github.io/kableExtra/awesome_table_in_html.html
kable(as.data.frame(df_train_numer_stats), digits = c(0, 1, 1, 1, 1, 1, 1, 1, 0)) %>% kable_styling()
```

### Visualize numerical variables:  violin plots, marked with quartiles
```{r fig.width=10, fig.height=10}

df_numer_tidy <- df_train_numeric %>% gather('feature', 'value')

fn_make_violin <- function(var_name, data_frame) {
  df_current_col <- data_frame %>% filter(feature == var_name)
  graph <- ggplot(data = df_current_col, 
                   aes(x = feature, y = value)) +
    geom_violin(na.rm = TRUE, draw_quantiles = c(0.25, 0.5, 0.75)) + 
    theme(axis.title.x = element_blank(), axis.title.y = element_blank())
  return(graph)
}

l_histograms <- lapply(colnames(df_train_numeric), fn_make_violin, data_frame = df_numer_tidy)

# # Assemble set of histograms
grid.arrange(grobs = l_histograms, nrow = 4)
```

TODO:  multivariate visualizations, correlations

## Multivariate descriptive statistics and correlations
```{r warning=FALSE,  fig.width=10, fig.height=10}
library(GGally)

ggpairs(df_train_numeric)

```

```{r fig.width=10, fig.height=10}
# https://www.r-bloggers.com/to-eat-or-not-to-eat-thats-the-question-measuring-the-association-between-categorical-variables/
  
library(GoodmanKruskal)

GKmatrix <- GKtauDataframe(as.data.frame(df_train_categ))
plot(GKmatrix, corrColors = "blue")
```

```{r}
# https://stackoverflow.com/a/32748027
chisqmatrix <- function(x) {
  names = colnames(x);  num = length(names)
  m = matrix(nrow=num,ncol=num,dimnames=list(names,names))
  for (i in 1:(num-1)) {
    for (j in (i+1):num) {
      # https://stackoverflow.com/a/4740272 for unlist() fix
      m[i,j] = chisq.test(unlist(x[,i]),unlist(x[,j]))$p.value
    }
  }
  return (m)
}
mat <-  chisqmatrix(df_train_categ) %>% tbl_df()
kable(mat, digits = rep(4, 11)) %>% kable_styling()

```

```{r}
library(graphics)
table(df_train_categ$day_of_week, df_train_categ$profession) %>% mosaicplot()
```

# Removing abnormal records and undesired features
From the data exploration above, we draw the following conclusions:
* Features `pdays` and `pmonths` are effectively the same (correlation = 1, unsurprisingly given their definitions), so we will remove `pmonths`.
* There's a strong correlation among `euribor.3m`, `cons price idx`, and `nr.employed`.  Additionally, `nr.employed` has a small standard deviation relative to its mean, which in the modeler's judgment is unlikely to be meaningful in prediction.  Therefore, this feature will be removed.
* The categorical values that occur most rarely in their particular features (`default = 'yes'`, `marital = 'unknown'`, and `schooling == 'illiterate') are too unbalanced to generate reliable predictive impact, and will also tend to cause R library errors if they occur in the validation set but not the training set.  Therefore, the very small number of affected rows will be discarded.
```{r}
df_train_orig <- df_train_orig %>% 
  select(-pmonths, -nr.employed) %>% 
  filter(default != 'yes' & marital != 'unknown' & 
           (schooling != 'illiterate' | is.na(schooling)))
```


## Extent of missing data
Count NAs per column, listing only the columns that have at least one NA.
```{r}
# Count NAs per column; show only the columns with at least 1
( df_incomplete <- df_train_orig %>% summarise_all(funs(sum(is.na(.)))) %>% select_if(function(col) sum(col) > 0) )
```

Tabulate rows by how many NAs they contain.
```{r}
# List of columns with NAs
l_cols_with_NAs <- colnames(df_incomplete)
# Count NAs per row
df_NA_per_row <- df_train_orig %>% 
  mutate_all(funs(ifelse(is.na(.), 1, 0))) %>% 
  transmute(num_NA = rowSums(.))
# Tabulate rows by how many NAs they contain
table(df_NA_per_row)

```

Conclusion:  nearly half the records contain at least one NA, so discarding incomplete records would be an extreme measure likely to bias the predictive model severely.  We will pursue other approaches.

# Split the data
Although the actual test data for this problem is found in a separate file, we also need to split the data for purposes of model selection.  We will split the "training" data into 70% for actual training and 30% for validation.
```{r}
library(caTools)
set.seed(101)
sample = sample.split(df_train_orig$responded, SplitRatio = 0.7)
df_train <- subset(df_train_orig, sample == TRUE)
df_validation <- subset(df_train_orig, sample == FALSE)

```

# Balance the sample
```{r}
library(unbalanced)
set.seed(875)
#configure sampling parameters
ubConf <- list(percOver=200, percUnder=200, k=2, perc=50, method="percPos", w=NULL)

# Prepare dataset in form required by 'unbalanced' package -- preliminary replacement of missing data
df_train_impute1 <- df_train %>% 
  mutate_if(is.character, replace_na, replace = 'NA_text') %>% 
  mutate(custAge = ifelse(is.na(custAge), median(custAge, na.rm = TRUE), custAge)) %>% 
  mutate_if(is.character, as.factor)

# Save factor level definitions
df_factor_levels <- df_train_impute1 %>% slice(1)
  
# Convert factors to numeric (required by 'unbalanced' package)  
df_train_impute1 <- df_train_impute1 %>% mutate_if(is.factor, as.numeric)

results <- ubRacing(responded ~., df_train_impute1 %>% as.data.frame(), 
                    "randomForest", positive = 2, ubConf=ubConf, ntree=50)
print(results$best)
```

```{r}
# if (results$best == 'ubNCL') {
if (0) {
  # Subtract one from response because this library requires (0,1) response vars
  rebal_result <- ubNCL(X = df_train_impute1 %>% select(-responded),
                          Y = df_train_impute1$responded - 1)
  # Add 1 to undo previous conversion of response var
  df_train_rebal <- bind_cols(rebal_result[['X']], (rebal_result[['Y']] + 1) %>% tbl_df() ) %>%
    rename(responded = value)
# } else if (results$best == 'ubSMOTE') {
} else if (1) {
  rebal_result <- ubBalance(X = df_train_impute1 %>% select(-responded),
                          Y = as.factor(df_train_impute1$responded - 1),
                          type = 'ubSMOTE', perc = 20)
  df_train_rebal <- bind_cols(rebal_result[['X']], (as.numeric(rebal_result[['Y']])) %>% tbl_df()) %>%
    rename(responded = value)
} else {
  stop('Unimplemented unbalancing method')
}

# Get column indices of categorical factors
l_factor_names <- df_factor_levels %>% select_if(is.factor) %>% names() 
l_factor_indices <- which(names(df_factor_levels) %in% l_factor_names)

# Convert numeric factor levels back to actual factor data
for (i in l_factor_indices) {
  df_train_rebal[i] <- levels(pull(df_factor_levels, i))[ df_train_rebal[i] %>% unlist()]
  # }
}
table(df_train_rebal$responded)
```


# Random Forest
```{r}
df_train_0 <- df_train %>% 
  mutate_if(is.character, as.factor) 

set.seed(101)
(qqq0 <- randomForest(responded ~ ., data = df_train_0, importance = TRUE, proximity = TRUE, na.action = na.omit))
```
```{r}
# Not rebalanced, but with NAs removed
df_train_00 <- df_train %>% 
  mutate_if(is.character, replace_na, replace = 'NA_text') %>% 
  mutate_if(is.character, as.factor) 
df_train_00 <- rfImpute(responded ~ ., df_train_00)

set.seed(1010)
# (qqq00 <- randomForest(responded ~ ., data = df_train_00, importance = TRUE, proximity = TRUE))
(
  qqq00 <- randomForest(x = df_train_00 %>% select(-responded), 
                       y = df_train_00 %>% pull(responded), 
                       xtest = df_validation_imputed %>% select(-responded), 
                       ytest = df_validation_imputed %>% pull(responded), 
                       importance = TRUE, 
                       proximity = TRUE,
                       ntree = 100)
)
```


```{r}
varImpPlot(qqq00,
           sort = T,
           main="Variable Importance",
           n.var=15)
fn_ROC_AUC((qqq00$test$votes %>% as.data.frame())$yes, df_validation_imputed$responded)
```

```{r}
df_train_1 <- df_train_rebal %>% 
  mutate_if(is.character, as.factor) 

set.seed(11111)
# qqq1 <- randomForest(responded ~ ., data = df_train_1, importance = TRUE, proximity = TRUE, na.action = na.omit)
# qqq1
(
  qqq1 <- randomForest(x = df_train_1 %>% select(-responded), 
                       y = df_train_1 %>% pull(responded), 
                       xtest = df_validation_imputed %>% select(-responded), 
                       ytest = df_validation_imputed %>% pull(responded), 
                       importance = TRUE, 
                       proximity = TRUE,
                       ntree = 100)
)

```

```{r}
varImpPlot(qqq1,
           sort = T,
           main="Variable Importance",
           n.var=15)
fn_ROC_AUC((qqq1$test$votes %>% as.data.frame())$yes, df_validation_imputed$responded)

```

```{r}
# Stratify
set.seed(22222)
qqq2 <- randomForest(responded ~ ., data = df_train_1, importance = TRUE, proximity = TRUE, 
                     na.action = na.omit, sampsize = c(1000, 250))
qqq2

```

```{r}
varImpPlot(qqq2,
           sort = T,
           main="Variable Importance",
           n.var=15)
```

```{r}
# Avoid some NAs
df_train_3 <- df_train %>% mutate_if(is.character, replace_na, replace = 'NA_text') %>% 
  mutate_if(is.character, as.factor) 

# Stratify
set.seed(33333)
qqq3 <- randomForest(responded ~ ., data = df_train_3, importance = TRUE, proximity = TRUE, 
                     na.action = na.omit, sampsize = c(2000, 500))
qqq3

```

```{r}
varImpPlot(qqq3,
           sort = T,
           main="Variable Importance",
           n.var=15)
```

```{r}
set.seed(44444)
qqq4 <- randomForest(responded ~ ., data = df_train_3, importance = TRUE, proximity = TRUE, 
                     na.action = na.omit)
qqq4

```

```{r}
varImpPlot(qqq4,
           sort = T,
           main="Variable Importance",
           n.var=15)
```

```{r eval=FALSE, include=FALSE}
# Impute any values missing in original data set
set.seed(55555)
qqq5_imputed <- rfImpute(responded ~ ., df_train_1)
set.seed(55556)
qqq5 <- randomForest(responded ~ ., data = qqq5_imputed, importance = TRUE, proximity = TRUE, 
                     na.action = na.omit, sampsize = c(2000, 500))
qqq5

```

```{r}
varImpPlot(qqq5,
           sort = T,
           main="Variable Importance",
           n.var=15)
```

```{r}
# Impute any values missing in original data set
set.seed(66666)
qqq6_imputed <- rfImpute(responded ~ ., df_train_3)
set.seed(66667)
qqq6 <- randomForest(responded ~ ., data = qqq6_imputed, importance = TRUE, proximity = TRUE, 
                     na.action = na.omit, sampsize = c(2000, 500))
qqq6

```

```{r fig.height=5, fig.width=5}
library(ROCR)
# https://rocr.bioinf.mpi-sb.mpg.de/

pred <- prediction(as.data.frame(qqq6$votes)$yes, qqq6_imputed$responded)
perf <- performance(pred, measure = "tpr", x.measure = "fpr")
auc <- performance(pred, measure = "auc")
# https://davidrroberts.wordpress.com/2015/09/22/quick-auc-function-in-r-with-rocr-package/
xline <- c(0,1)
yline <- xline
plot(perf, colorize = T)
text(1,0.15,labels=paste("AUC = ",round(auc@y.values[[1]],digits=3),sep=""),adj=1)
lines(xline, yline, col = 'grey')
 
```

```{r}
varImpPlot(qqq6,
           sort = T,
           main="Variable Importance",
           n.var=15)
```

```{r}
# Impute missing ages by median
set.seed(77777)
qqq7_imputed <- df_train_3 %>% mutate(custAge = ifelse(is.na(custAge), median(custAge, na.rm = TRUE), custAge))
set.seed(77778)
qqq7 <- randomForest(responded ~ ., data = qqq6_imputed, importance = TRUE, proximity = TRUE, 
                     na.action = na.omit, sampsize = c(2000, 500))
qqq7

```

```{r}
varImpPlot(qqq7,
           sort = T,
           main="Variable Importance",
           n.var=15)
```




# Appendix:  Reproducibility
```{r}
R.version
```

```{r}
Sys.info()
```

```{r}
date()
```

TODO:  add package versions
TODO:  add git repo status


```{r eval=FALSE, include=FALSE}
Standard R Notebook boilerplate inserted by RStudio:
  
This is an [R Markdown](http://rmarkdown.rstudio.com) Notebook. When you execute code within the notebook, the results appear beneath the code. 

Try executing this chunk by clicking the *Run* button within the chunk or by placing your cursor inside it and pressing *Ctrl+Shift+Enter*. 

# ```{r}
plot(cars)
# ```

Add a new chunk by clicking the *Insert Chunk* button on the toolbar or by pressing *Ctrl+Alt+I*.

When you save the notebook, an HTML file containing the code and output will be saved alongside it (click the *Preview* button or press *Ctrl+Shift+K* to preview the HTML file).

The preview shows you a rendered HTML copy of the contents of the editor. Consequently, unlike *Knit*, *Preview* does not run any R code chunks. Instead, the output of the chunk when it was last run in the editor is displayed.

```


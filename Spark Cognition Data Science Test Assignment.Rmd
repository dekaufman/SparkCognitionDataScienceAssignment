---
title: "SparkCognition Data Science Test Project:  Targeting of Insurance Marketing"
output: html_notebook
---

```{r setup, message=FALSE, warning=FALSE}
library(tidyverse)
library(gridExtra)
library(knitr)
library(kableExtra)
setwd('C:/Users/David/Documents/Me/Energy/Jobs/2018/SparkCognition/SparkCognitionDataScienceAssignment')
```

### Ingest training data and report dimensions
```{r, message=FALSE, warning=FALSE}
df_train <- read_csv('marketing_training.csv')
dim(df_train)
```
## Generate descriptive statistics on individual features
Separate the features into categorical and numeric, for separate descriptive methods
```{r}
df_train_numeric <- df_train %>% select_if(is.numeric)
df_train_categ <- df_train %>% select_if(is.character)
```

### Summarize categorical variables
```{r}
# Make tidy
df_cat_tidy <- df_train_categ %>% 
  gather('feature', 'value', 1:11)
# Count values
df_cat_dists <- df_cat_tidy %>% 
  group_by(feature, value) %>% 
  summarise(count = n()) %>% 
  ungroup() %>% 
  arrange(feature, desc(count))
# Compute distributions
df_cat_dists <- df_cat_dists %>% 
  group_by(feature) %>% 
  mutate(share = count / sum(count))
```

### Visualize categorical variables
```{r fig.width=10, fig.height=10}
fn_make_hist <- function(var_name, data_frame) {
  df_current_col <- data_frame %>% filter(feature == var_name)
  graph <- ggplot(data = df_current_col, 
                   aes(x = reorder(value, -share), y = share)) +
    geom_col() +
    stat_identity(geom="text", aes(label=count), vjust=-0.5, size = 3) +
    labs(x = var_name) +
    coord_cartesian(ylim = c(0, 1))
  if (nrow(df_current_col) > 4) {
    graph <- graph + theme(axis.text.x = element_text(angle = 45, hjust = 1))
  } 
  return(graph)
}

l_histograms <- lapply(colnames(df_train_categ), fn_make_hist, data_frame = df_cat_dists)

# Assemble set of histograms
grid.arrange(grobs = l_histograms, nrow = 4)
```

### Descriptive stats for numerical variables
```{r warning=FALSE, rows.print = 25, results = 'asis'}
# Source:  https://stackoverflow.com/a/34594642

# Compute quantiles, etc.
df_train_numer_stats <- df_train_numeric %>%
  summarise_all(funs(min = min, 
                     q25 = quantile(., 0.25), 
                     median = median, 
                     q75 = quantile(., 0.75), 
                     max = max,
                     mean = mean, 
                     sd = sd), 
                 na.rm = TRUE)

# Count NAs by column
df_train_numer_num_na <- df_train_numeric %>%
  summarise_all(funs(numNA = sum(is.na(.))))

df_train_numer_stats <- df_train_numer_stats %>% bind_cols(df_train_numer_num_na)

# Reshape back to tidy format
df_train_numer_stats <- df_train_numer_stats %>% 
  gather(stat, val) %>%
  separate(stat, into = c("var", "stat"), sep = "_") %>%
  spread(stat, val) %>%
  select(var, min, q25, median, q75, max, mean, sd, numNA) # reorder columns

# Pretty table printing; cf. http://haozhu233.github.io/kableExtra/awesome_table_in_html.html
kable(as.data.frame(df_train_numer_stats), digits = c(0, 1, 1, 1, 1, 1, 1, 1, 0)) %>% kable_styling()
```

### Visualize numerical variables:  violin plots, marked with quartiles
```{r fig.width=10, fig.height=10}

df_numer_tidy <- df_train_numeric %>% gather('feature', 'value')

fn_make_violin <- function(var_name, data_frame) {
  df_current_col <- data_frame %>% filter(feature == var_name)
  graph <- ggplot(data = df_current_col, 
                   aes(x = feature, y = value)) +
    geom_violin(na.rm = TRUE, draw_quantiles = c(0.25, 0.5, 0.75)) + 
    theme(axis.title.x = element_blank(), axis.title.y = element_blank())
  return(graph)
}

l_histograms <- lapply(colnames(df_train_numeric), fn_make_violin, data_frame = df_numer_tidy)

# # Assemble set of histograms
grid.arrange(grobs = l_histograms, nrow = 4)
```

TODO:  multivariate visualizations, correlations

## Multivariate descriptive statistics and correlations
```{r warning=FALSE,  fig.width=10, fig.height=10}
library(GGally)

ggpairs(df_train_numeric)

```

```{r fig.width=10, fig.height=10}
# https://www.r-bloggers.com/to-eat-or-not-to-eat-thats-the-question-measuring-the-association-between-categorical-variables/
  
library(GoodmanKruskal)

GKmatrix <- GKtauDataframe(as.data.frame(df_train_categ))
plot(GKmatrix, corrColors = "blue")
```

```{r}
# https://stackoverflow.com/a/32748027
chisqmatrix <- function(x) {
  names = colnames(x);  num = length(names)
  m = matrix(nrow=num,ncol=num,dimnames=list(names,names))
  for (i in 1:(num-1)) {
    for (j in (i+1):num) {
      # https://stackoverflow.com/a/4740272 for unlist() fix
      m[i,j] = chisq.test(unlist(x[,i]),unlist(x[,j]))$p.value
    }
  }
  return (m)
}
mat <-  chisqmatrix(df_train_categ) %>% tbl_df()
kable(mat, digits = rep(4, 11)) %>% kable_styling()

```

```{r}
library(graphics)
table(df_train_categ$day_of_week, df_train_categ$profession) %>% mosaicplot()
```



## Extent of missing data
Count NAs per column, listing only the columns that have at least one NA.
```{r}
# Count NAs per column; show only the columns with at least 1
( df_incomplete <- df_train %>% summarise_all(funs(sum(is.na(.)))) %>% select_if(function(col) sum(col) > 0) )
```

Tabulate rows by how many NAs they contain.
```{r}
# List of columns with NAs
l_cols_with_NAs <- colnames(df_incomplete)
# Count NAs per row
df_NA_per_row <- df_train %>% 
  mutate_all(funs(ifelse(is.na(.), 1, 0))) %>% 
  transmute(num_NA = rowSums(.))
# Tabulate rows by how many NAs they contain
table(df_NA_per_row)

```

Conclusion:  nearly half the records contain at least one NA, so discarding incomplete records would be an extreme measure likely to bias the predictive model severely.

# Random Forest
```{r}
library(randomForest)

df_train_1 <- df_train %>% 
  mutate_if(is.character, as.factor) 

set.seed(11111)
qqq1 <- randomForest(responded ~ ., data = df_train_1, importance = TRUE, proximity = TRUE, na.action = na.omit)
qqq1[['confusion']]
```

```{r}
varImpPlot(qqq1,
           sort = T,
           main="Variable Importance",
           n.var=15)
```

```{r}
# Stratify
set.seed(22222)
qqq2 <- randomForest(responded ~ ., data = df_train_1, importance = TRUE, proximity = TRUE, 
                     na.action = na.omit, sampsize = c(1000, 250))
qqq2[['confusion']]

```

```{r}
varImpPlot(qqq2,
           sort = T,
           main="Variable Importance",
           n.var=15)
```

```{r}
# Avoid some NAs
df_train_3 <- df_train %>% mutate_if(is.character, replace_na, replace = 'NA_text') %>% 
  mutate_if(is.character, as.factor) 

# Stratify
set.seed(33333)
qqq3 <- randomForest(responded ~ ., data = df_train_3, importance = TRUE, proximity = TRUE, 
                     na.action = na.omit, sampsize = c(2000, 500))
qqq3[['confusion']]

```

```{r}
varImpPlot(qqq3,
           sort = T,
           main="Variable Importance",
           n.var=15)
```

```{r}
set.seed(44444)
qqq4 <- randomForest(responded ~ ., data = df_train_3, importance = TRUE, proximity = TRUE, 
                     na.action = na.omit)
qqq4[['confusion']]

```

```{r}
varImpPlot(qqq4,
           sort = T,
           main="Variable Importance",
           n.var=15)
```

```{r eval=FALSE, include=FALSE}
# Impute any values missing in original data set
set.seed(55555)
qqq5_imputed <- rfImpute(responded ~ ., df_train_1)
set.seed(55556)
qqq5 <- randomForest(responded ~ ., data = qqq5_imputed, importance = TRUE, proximity = TRUE, 
                     na.action = na.omit, sampsize = c(2000, 500))
qqq5[['confusion']]

```

```{r}
varImpPlot(qqq5,
           sort = T,
           main="Variable Importance",
           n.var=15)
```

```{r}
# Impute any values missing in original data set
set.seed(66666)
qqq6_imputed <- rfImpute(responded ~ ., df_train_3)
set.seed(66667)
qqq6 <- randomForest(responded ~ ., data = qqq6_imputed, importance = TRUE, proximity = TRUE, 
                     na.action = na.omit, sampsize = c(2000, 500))
qqq6[['confusion']]

```

```{r}
varImpPlot(qqq6,
           sort = T,
           main="Variable Importance",
           n.var=15)
```

```{r}
# Impute missing ages by median
set.seed(77777)
qqq7_imputed <- df_train_3 %>% mutate(custAge = ifelse(is.na(custAge), median(custAge, na.rm = TRUE), custAge))
set.seed(77777)
qqq7 <- randomForest(responded ~ ., data = qqq6_imputed, importance = TRUE, proximity = TRUE, 
                     na.action = na.omit, sampsize = c(2000, 500))
qqq7[['confusion']]

```

```{r}
varImpPlot(qqq7,
           sort = T,
           main="Variable Importance",
           n.var=15)
```




# Appendix:  Reproducibility
```{r}
R.version
```

```{r}
Sys.info()
```

```{r}
date()
```

TODO:  add package versions
TODO:  add git repo status


```{r eval=FALSE, include=FALSE}
Standard R Notebook boilerplate inserted by RStudio:
  
This is an [R Markdown](http://rmarkdown.rstudio.com) Notebook. When you execute code within the notebook, the results appear beneath the code. 

Try executing this chunk by clicking the *Run* button within the chunk or by placing your cursor inside it and pressing *Ctrl+Shift+Enter*. 

# ```{r}
plot(cars)
# ```

Add a new chunk by clicking the *Insert Chunk* button on the toolbar or by pressing *Ctrl+Alt+I*.

When you save the notebook, an HTML file containing the code and output will be saved alongside it (click the *Preview* button or press *Ctrl+Shift+K* to preview the HTML file).

The preview shows you a rendered HTML copy of the contents of the editor. Consequently, unlike *Knit*, *Preview* does not run any R code chunks. Instead, the output of the chunk when it was last run in the editor is displayed.

```

